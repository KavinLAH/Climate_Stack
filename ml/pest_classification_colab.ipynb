{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ› Pest Classification Model â€” Full Pipeline\n",
                "\n",
                "**GPU-accelerated training, evaluation, quantization & benchmarking**\n",
                "\n",
                "1. Upload `curated_data.zip` (from local machine)\n",
                "2. Train EfficientNetB0 with transfer learning (20 + 10 epochs)\n",
                "3. Evaluate top-1 & top-3 accuracy\n",
                "4. Quantize to INT8 TFLite\n",
                "5. Benchmark inference latency\n",
                "6. Download `pest_model.tflite` + `labels.json`\n",
                "\n",
                "> **Runtime â†’ Change runtime type â†’ T4 GPU** before running!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1ï¸âƒ£ Upload & Extract Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "import zipfile, os\n",
                "\n",
                "print(\"Upload curated_data.zip from your local machine...\")\n",
                "uploaded = files.upload()\n",
                "\n",
                "with zipfile.ZipFile('curated_data.zip', 'r') as z:\n",
                "    z.extractall('.')\n",
                "\n",
                "# Verify\n",
                "for split in ['train', 'val', 'test']:\n",
                "    n = sum(len(f) for _, _, f in os.walk(f'curated_data/{split}'))\n",
                "    print(f'{split}: {n} images')\n",
                "\n",
                "print('\\nâœ… Dataset ready!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2ï¸âƒ£ Setup & GPU Check"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import time\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import tensorflow as tf\n",
                "from sklearn.metrics import classification_report, confusion_matrix\n",
                "\n",
                "print(f\"TensorFlow: {tf.__version__}\")\n",
                "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")\n",
                "\n",
                "# Constants\n",
                "IMG_SIZE = 224\n",
                "BATCH_SIZE = 32\n",
                "NUM_CLASSES = 18\n",
                "\n",
                "# Load labels\n",
                "with open('curated_data/labels.json') as f:\n",
                "    LABELS = json.load(f)\n",
                "CLASS_NAMES = [LABELS[str(i)] for i in range(NUM_CLASSES)]\n",
                "print(f\"\\n{NUM_CLASSES} classes: {CLASS_NAMES}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3ï¸âƒ£ Load Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "    'curated_data/train', image_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE, label_mode='int', shuffle=True, seed=42)\n",
                "\n",
                "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "    'curated_data/val', image_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE, label_mode='int', shuffle=False)\n",
                "\n",
                "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "    'curated_data/test', image_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE, label_mode='int', shuffle=False)\n",
                "\n",
                "AUTOTUNE = tf.data.AUTOTUNE\n",
                "train_ds = train_ds.prefetch(AUTOTUNE)\n",
                "val_ds = val_ds.prefetch(AUTOTUNE)\n",
                "test_ds = test_ds.prefetch(AUTOTUNE)\n",
                "\n",
                "# Class weights\n",
                "all_labels = []\n",
                "for _, labels in train_ds:\n",
                "    all_labels.extend(labels.numpy().tolist())\n",
                "counts = np.bincount(all_labels, minlength=NUM_CLASSES)\n",
                "total = len(all_labels)\n",
                "class_weights = {i: total / (NUM_CLASSES * counts[i]) if counts[i] > 0 else 1.0 for i in range(NUM_CLASSES)}\n",
                "print(f\"\\nTotal training images: {total}\")\n",
                "print(f\"Class weight range: {min(class_weights.values()):.2f} â€“ {max(class_weights.values()):.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4ï¸âƒ£ Build Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "base_model = tf.keras.applications.EfficientNetB0(\n",
                "    include_top=False, weights='imagenet',\n",
                "    input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
                "base_model.trainable = False\n",
                "\n",
                "model = tf.keras.Sequential([\n",
                "    base_model,\n",
                "    tf.keras.layers.GlobalAveragePooling2D(),\n",
                "    tf.keras.layers.Dropout(0.3),\n",
                "    tf.keras.layers.Dense(128, activation='relu'),\n",
                "    tf.keras.layers.Dropout(0.2),\n",
                "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax'),\n",
                "])\n",
                "\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy'])\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5ï¸âƒ£ Phase 1: Train Classifier Head (base frozen)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "HEAD_EPOCHS = 20\n",
                "\n",
                "callbacks_head = [\n",
                "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1),\n",
                "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n",
                "    tf.keras.callbacks.ModelCheckpoint('pest_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
                "]\n",
                "\n",
                "print(f\"Phase 1: Training classifier head for {HEAD_EPOCHS} epochs...\")\n",
                "hist1 = model.fit(train_ds, validation_data=val_ds, epochs=HEAD_EPOCHS,\n",
                "                  class_weight=class_weights, callbacks=callbacks_head)\n",
                "print(f\"\\nâœ… Phase 1 done â€” Best val_accuracy: {max(hist1.history['val_accuracy']):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6ï¸âƒ£ Phase 2: Fine-tune Last 20 Layers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "FT_EPOCHS = 10\n",
                "\n",
                "base_model.trainable = True\n",
                "for layer in base_model.layers[:-20]:\n",
                "    layer.trainable = False\n",
                "\n",
                "model.compile(\n",
                "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
                "    loss='sparse_categorical_crossentropy',\n",
                "    metrics=['accuracy'])\n",
                "\n",
                "callbacks_ft = [\n",
                "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1),\n",
                "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n",
                "    tf.keras.callbacks.ModelCheckpoint('pest_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
                "]\n",
                "\n",
                "print(f\"Phase 2: Fine-tuning last 20 layers for {FT_EPOCHS} epochs...\")\n",
                "hist2 = model.fit(train_ds, validation_data=val_ds, epochs=FT_EPOCHS,\n",
                "                  class_weight=class_weights, callbacks=callbacks_ft)\n",
                "print(f\"\\nâœ… Phase 2 done â€” Best val_accuracy: {max(hist2.history['val_accuracy']):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7ï¸âƒ£ Training Curves"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "offset = 0\n",
                "for name, hist, color in [('Head', hist1, '#2196F3'), ('Fine-tune', hist2, '#FF5722')]:\n",
                "    epochs = range(offset+1, offset+len(hist.history['accuracy'])+1)\n",
                "    ax1.plot(epochs, hist.history['accuracy'], '-o', color=color, label=f'{name} train', ms=3)\n",
                "    ax1.plot(epochs, hist.history['val_accuracy'], '--s', color=color, label=f'{name} val', ms=3, alpha=0.7)\n",
                "    ax2.plot(epochs, hist.history['loss'], '-o', color=color, label=f'{name} train', ms=3)\n",
                "    ax2.plot(epochs, hist.history['val_loss'], '--s', color=color, label=f'{name} val', ms=3, alpha=0.7)\n",
                "    offset += len(hist.history['accuracy'])\n",
                "\n",
                "ax1.set_title('Accuracy'); ax1.set_xlabel('Epoch'); ax1.legend(); ax1.grid(alpha=0.3)\n",
                "ax2.set_title('Loss'); ax2.set_xlabel('Epoch'); ax2.legend(); ax2.grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_curves.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8ï¸âƒ£ Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model\n",
                "model = tf.keras.models.load_model('pest_model.keras')\n",
                "\n",
                "all_labels, all_probs = [], []\n",
                "for images, labels in test_ds:\n",
                "    probs = model.predict(images, verbose=0)\n",
                "    all_probs.append(probs)\n",
                "    all_labels.extend(labels.numpy().tolist())\n",
                "\n",
                "all_probs = np.concatenate(all_probs, axis=0)\n",
                "all_labels = np.array(all_labels)\n",
                "all_preds = np.argmax(all_probs, axis=1)\n",
                "\n",
                "top1 = np.mean(all_preds == all_labels)\n",
                "top3_preds = np.argsort(all_probs, axis=1)[:, -3:]\n",
                "top3 = np.mean([all_labels[i] in top3_preds[i] for i in range(len(all_labels))])\n",
                "\n",
                "print(f\"Top-1 Accuracy: {top1:.4f} ({top1*100:.1f}%)\")\n",
                "print(f\"Top-3 Accuracy: {top3:.4f} ({top3*100:.1f}%)\")\n",
                "print(f\"Top-3 Target (>85%): {'âœ… PASSED' if top3 > 0.85 else 'âŒ BELOW TARGET'}\")\n",
                "print()\n",
                "print(classification_report(all_labels, all_preds, target_names=CLASS_NAMES, digits=3))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cm = confusion_matrix(all_labels, all_preds)\n",
                "fig, ax = plt.subplots(figsize=(14, 12))\n",
                "im = ax.imshow(cm, cmap='Blues')\n",
                "fig.colorbar(im, ax=ax, shrink=0.8)\n",
                "ax.set_xticks(range(NUM_CLASSES)); ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right', fontsize=8)\n",
                "ax.set_yticks(range(NUM_CLASSES)); ax.set_yticklabels(CLASS_NAMES, fontsize=8)\n",
                "thresh = cm.max() / 2\n",
                "for i in range(cm.shape[0]):\n",
                "    for j in range(cm.shape[1]):\n",
                "        ax.text(j, i, str(cm[i,j]), ha='center', va='center', fontsize=7,\n",
                "                color='white' if cm[i,j] > thresh else 'black')\n",
                "ax.set_ylabel('True'); ax.set_xlabel('Predicted'); ax.set_title('Confusion Matrix')\n",
                "plt.tight_layout()\n",
                "plt.savefig('confusion_matrix.png', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9ï¸âƒ£ Quantize to INT8 TFLite"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Representative dataset for INT8 calibration\n",
                "def representative_dataset():\n",
                "    cal_ds = tf.keras.utils.image_dataset_from_directory(\n",
                "        'curated_data/train', image_size=(IMG_SIZE, IMG_SIZE),\n",
                "        batch_size=1, label_mode=None, shuffle=True, seed=42)\n",
                "    for i, images in enumerate(cal_ds):\n",
                "        yield [images.numpy().astype(np.float32)]\n",
                "        if i >= 200: break\n",
                "\n",
                "# Float32 conversion\n",
                "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
                "tflite_float = converter.convert()\n",
                "with open('pest_model_float32.tflite', 'wb') as f:\n",
                "    f.write(tflite_float)\n",
                "print(f\"Float32 TFLite: {len(tflite_float)/1024/1024:.1f} MB\")\n",
                "\n",
                "# INT8 conversion\n",
                "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
                "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
                "converter.representative_dataset = representative_dataset\n",
                "converter.target_spec.supported_ops = [\n",
                "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
                "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
                "]\n",
                "converter.inference_input_type = tf.uint8\n",
                "converter.inference_output_type = tf.float32\n",
                "\n",
                "print(\"Quantizing with 200 calibration images...\")\n",
                "tflite_int8 = converter.convert()\n",
                "with open('pest_model.tflite', 'wb') as f:\n",
                "    f.write(tflite_int8)\n",
                "print(f\"INT8 TFLite: {len(tflite_int8)/1024/1024:.1f} MB\")\n",
                "print(f\"Compression: {len(tflite_float)/len(tflite_int8):.1f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Validate Quantized Accuracy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "interpreter = tf.lite.Interpreter(model_path='pest_model.tflite')\n",
                "interpreter.allocate_tensors()\n",
                "inp = interpreter.get_input_details()\n",
                "out = interpreter.get_output_details()\n",
                "\n",
                "correct, total_count = 0, 0\n",
                "for images, labels in test_ds:\n",
                "    for i in range(images.shape[0]):\n",
                "        img = images[i:i+1].numpy()\n",
                "        if inp[0]['dtype'] == np.uint8:\n",
                "            s, z = inp[0]['quantization']\n",
                "            img = (img / s + z).astype(np.uint8)\n",
                "        else:\n",
                "            img = img.astype(np.float32)\n",
                "        interpreter.set_tensor(inp[0]['index'], img)\n",
                "        interpreter.invoke()\n",
                "        pred = np.argmax(interpreter.get_tensor(out[0]['index'])[0])\n",
                "        if pred == labels[i].numpy():\n",
                "            correct += 1\n",
                "        total_count += 1\n",
                "\n",
                "int8_acc = correct / total_count\n",
                "drop = (top1 - int8_acc) * 100\n",
                "print(f\"Keras accuracy:  {top1:.4f}\")\n",
                "print(f\"INT8 accuracy:   {int8_acc:.4f}\")\n",
                "print(f\"Drop:            {drop:.1f}%  {'âœ… Within budget' if drop <= 3 else 'âš ï¸ Exceeds 3%'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”Ÿ Benchmark Inference Latency"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Benchmark on CPU (simulates mobile device)\n",
                "interpreter = tf.lite.Interpreter(model_path='pest_model.tflite', num_threads=1)\n",
                "interpreter.allocate_tensors()\n",
                "inp = interpreter.get_input_details()\n",
                "out = interpreter.get_output_details()\n",
                "\n",
                "# Warmup\n",
                "dummy = np.zeros((1, IMG_SIZE, IMG_SIZE, 3), dtype=inp[0]['dtype'])\n",
                "for _ in range(5):\n",
                "    interpreter.set_tensor(inp[0]['index'], dummy)\n",
                "    interpreter.invoke()\n",
                "\n",
                "# Timed runs\n",
                "latencies = []\n",
                "for images, _ in test_ds.take(4):  # ~128 images\n",
                "    for i in range(images.shape[0]):\n",
                "        img = images[i:i+1].numpy()\n",
                "        if inp[0]['dtype'] == np.uint8:\n",
                "            s, z = inp[0]['quantization']\n",
                "            img = (img / s + z).astype(np.uint8)\n",
                "        else:\n",
                "            img = img.astype(np.float32)\n",
                "        t0 = time.perf_counter()\n",
                "        interpreter.set_tensor(inp[0]['index'], img)\n",
                "        interpreter.invoke()\n",
                "        _ = interpreter.get_tensor(out[0]['index'])\n",
                "        latencies.append((time.perf_counter() - t0) * 1000)\n",
                "\n",
                "latencies = np.array(latencies)\n",
                "print(f\"Inference Latency (single-thread CPU):\")\n",
                "print(f\"  Mean:   {latencies.mean():.1f} ms\")\n",
                "print(f\"  Median: {np.median(latencies):.1f} ms\")\n",
                "print(f\"  P95:    {np.percentile(latencies, 95):.1f} ms\")\n",
                "print(f\"  Target (<500ms): {'âœ… MET' if latencies.mean() < 500 else 'âš ï¸ EXCEEDED'}\")\n",
                "\n",
                "# Summary\n",
                "f_size = os.path.getsize('pest_model_float32.tflite') / 1024 / 1024\n",
                "q_size = os.path.getsize('pest_model.tflite') / 1024 / 1024\n",
                "print(f\"\\n{'Model':<20} {'Size (MB)':>10} {'Latency (ms)':>13} {'Accuracy':>10}\")\n",
                "print('-'*56)\n",
                "print(f\"{'Keras (full)':20} {'â€”':>10} {'â€”':>13} {top1:>10.1%}\")\n",
                "print(f\"{'TFLite Float32':20} {f_size:>10.1f} {'â€”':>13} {'â€”':>10}\")\n",
                "print(f\"{'TFLite INT8':20} {q_size:>10.1f} {latencies.mean():>13.1f} {int8_acc:>10.1%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“¦ Download Artifacts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save benchmark report\n",
                "report = {\n",
                "    'keras_top1_accuracy': float(top1),\n",
                "    'keras_top3_accuracy': float(top3),\n",
                "    'int8_accuracy': float(int8_acc),\n",
                "    'accuracy_drop_pct': float(drop),\n",
                "    'int8_model_size_mb': float(q_size),\n",
                "    'mean_latency_ms': float(latencies.mean()),\n",
                "    'median_latency_ms': float(np.median(latencies)),\n",
                "    'p95_latency_ms': float(np.percentile(latencies, 95)),\n",
                "}\n",
                "with open('benchmark_report.json', 'w') as f:\n",
                "    json.dump(report, f, indent=2)\n",
                "\n",
                "# Save labels.json at top level\n",
                "import shutil\n",
                "shutil.copy('curated_data/labels.json', 'labels.json')\n",
                "\n",
                "print(\"ðŸ“¥ Downloading model and labels...\")\n",
                "files.download('pest_model.tflite')\n",
                "files.download('labels.json')\n",
                "files.download('benchmark_report.json')\n",
                "files.download('training_curves.png')\n",
                "files.download('confusion_matrix.png')\n",
                "print(\"\\nâœ… All done! Files downloaded.\")"
            ]
        }
    ]
}